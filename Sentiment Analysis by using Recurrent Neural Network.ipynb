{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=pd.read_csv(\"data/processed_file.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26247</th>\n",
       "      <td>Fame is one of the best movies I've seen about...</td>\n",
       "      <td>-1</td>\n",
       "      <td>11122_8.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>This movie fully deserves to be one of the top...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7811_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34590</th>\n",
       "      <td>in a time of predictable movies, in which abou...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7382_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>I saw this on TV the other nightÂ",
       " or rather I...</td>\n",
       "      <td>0</td>\n",
       "      <td>2501_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>I am a huge fan of Simon Pegg and have watched...</td>\n",
       "      <td>1</td>\n",
       "      <td>9728_7.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file\n",
       "26247  Fame is one of the best movies I've seen about...     -1  11122_8.txt\n",
       "35067  This movie fully deserves to be one of the top...     -1  7811_10.txt\n",
       "34590  in a time of predictable movies, in which abou...     -1  7382_10.txt\n",
       "16668  I saw this on TV the other nightÂ\n",
       " or rather I...      0   2501_1.txt\n",
       "12196  I am a huge fan of Simon Pegg and have watched...      1   9728_7.txt"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 3)\n",
      "(10000, 3)\n",
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "reviews = reviews[[\"review\", \"label\", \"file\"]].sample(frac=1, random_state=1)\n",
    "train = reviews[reviews.label!=-1].sample(frac=0.6, random_state=1)\n",
    "valid = reviews[reviews.label!=-1].drop(train.index)\n",
    "test = reviews[reviews.label==-1]\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "The next step is data preprocessing. The following class behaves like your typical SKLearn vectorizer.\n",
    "\n",
    "It can perform the following operations.\n",
    "\n",
    "Discard non alpha-numeric characters\n",
    "Set everything to lower case\n",
    "Stems all words using PorterStemmer, and change the stems back to the most occurring existent word.\n",
    "Discard non-Egnlish words (not by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\it\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet \n",
    "allEnglishWords = words.words() + [w for w in wordnet.words()]\n",
    "allEnglishWords = np.unique([x.lower() for x in allEnglishWords])\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "class Preprocessor(object):\n",
    "    ''' Preprocess data for NLP tasks. '''\n",
    "\n",
    "    def __init__(self, alpha=True, lower=True, stemmer=True, english=False):\n",
    "        self.alpha = alpha\n",
    "        self.lower = lower\n",
    "        self.stemmer = stemmer\n",
    "        self.english = english\n",
    "        \n",
    "        self.uniqueWords = None\n",
    "        self.uniqueStems = None\n",
    "        \n",
    "    def fit(self, texts):\n",
    "        texts = self._doAlways(texts)\n",
    "\n",
    "        allwords = pd.DataFrame({\"word\": np.concatenate(texts.apply(lambda x: x.split()).values)})\n",
    "        self.uniqueWords = allwords.groupby([\"word\"]).size().rename(\"count\").reset_index()\n",
    "        self.uniqueWords = self.uniqueWords[self.uniqueWords[\"count\"]>1]\n",
    "        if self.stemmer:\n",
    "            self.uniqueWords[\"stem\"] = self.uniqueWords.word.apply(lambda x: PorterStemmer().stem(x)).values\n",
    "            self.uniqueWords.sort_values([\"stem\", \"count\"], inplace=True, ascending=False)\n",
    "            self.uniqueStems = self.uniqueWords.groupby(\"stem\").first()\n",
    "        \n",
    "        #if self.english: self.words[\"english\"] = np.in1d(self.words[\"mode\"], allEnglishWords)\n",
    "        print(\"Fitted.\")\n",
    "            \n",
    "    def transform(self, texts):\n",
    "        texts = self._doAlways(texts)\n",
    "        if self.stemmer:\n",
    "            allwords = np.concatenate(texts.apply(lambda x: x.split()).values)\n",
    "            uniqueWords = pd.DataFrame(index=np.unique(allwords))\n",
    "            uniqueWords[\"stem\"] = pd.Series(uniqueWords.index).apply(lambda x: PorterStemmer().stem(x)).values\n",
    "            uniqueWords[\"mode\"] = uniqueWords.stem.apply(lambda x: self.uniqueStems.loc[x, \"word\"] if x in self.uniqueStems.index else \"\")\n",
    "            texts = texts.apply(lambda x: \" \".join([uniqueWords.loc[y, \"mode\"] for y in x.split()]))\n",
    "        #if self.english: texts = self.words.apply(lambda x: \" \".join([y for y in x.split() if self.words.loc[y,\"english\"]]))\n",
    "        print(\"Transformed.\")\n",
    "        return(texts)\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        texts = self._doAlways(texts)\n",
    "        self.fit(texts)\n",
    "        texts = self.transform(texts)\n",
    "        return(texts)\n",
    "    \n",
    "    def _doAlways(self, texts):\n",
    "        # Remove parts between <>'s\n",
    "        texts = texts.apply(lambda x: re.sub('<.*?>', ' ', x))\n",
    "        # Keep letters and digits only.\n",
    "        if self.alpha: texts = texts.apply(lambda x: re.sub('[^a-zA-Z0-9 ]+', ' ', x))\n",
    "        # Set everything to lower case\n",
    "        if self.lower: texts = texts.apply(lambda x: x.lower())\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocessor(alpha=True, lower=True, stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted.\n",
      "Transformed.\n",
      "Transformed.\n",
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainX = preprocess.fit_transform(train.review)\n",
    "validX = preprocess.transform(valid.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15710    the earlier part of the film was rather enjoy ...\n",
       "14400    there is only one reason to watch this movie i...\n",
       "313      if your idea of a thriller is car chase explos...\n",
       "14601    sadly the print of the film we were go to watc...\n",
       "20691    sure one of the most ill advise remake of a cl...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 15000\n",
       "unique                                                14964\n",
       "top       this show come up with interesting location as...\n",
       "freq                                                      3\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38409, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15085</th>\n",
       "      <td>disappointingly</td>\n",
       "      <td>8</td>\n",
       "      <td>disappointingli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15083</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>581</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15084</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>257</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15086</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>245</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15082</th>\n",
       "      <td>disappoint</td>\n",
       "      <td>62</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15089</th>\n",
       "      <td>disappoints</td>\n",
       "      <td>23</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15088</th>\n",
       "      <td>disappointments</td>\n",
       "      <td>14</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  count             stem\n",
       "15085  disappointingly      8  disappointingli\n",
       "15083     disappointed    581       disappoint\n",
       "15084    disappointing    257       disappoint\n",
       "15086   disappointment    245       disappoint\n",
       "15082       disappoint     62       disappoint\n",
       "15089      disappoints     23       disappoint\n",
       "15088  disappointments     14       disappoint"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(preprocess.uniqueWords.shape)\n",
    "preprocess.uniqueWords[preprocess.uniqueWords.word.str.contains(\"disappoint\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25433, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>disappoint</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointingli</th>\n",
       "      <td>disappointingly</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            word  count\n",
       "stem                                   \n",
       "disappoint          disappointed    581\n",
       "disappointingli  disappointingly      8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(preprocess.uniqueStems.shape)\n",
    "preprocess.uniqueStems[preprocess.uniqueStems.word.str.contains(\"disappoint\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Next, we take the preprocessed texts as input and calculate their TF-IDF's (info). We retain 10000 features per text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = text.ENGLISH_STOP_WORDS.union([\"thats\",\"weve\",\"dont\",\"lets\",\"youre\",\"im\",\"thi\",\"ha\",\n",
    "    \"wa\",\"st\",\"ask\",\"want\",\"like\",\"thank\",\"know\",\"susan\",\"ryan\",\"say\",\"got\",\"ought\",\"ive\",\"theyre\"])\n",
    "tfidf = TfidfVectorizer(min_df=2, max_features=10000, stop_words=stop_words) #, ngram_range=(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainX = tfidf.fit_transform(trainX).toarray()\n",
    "validX = tfidf.transform(validX).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 10000)\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(validX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = train.label\n",
    "validY = valid.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 10000) (15000,)\n",
      "(10000, 10000) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape)\n",
    "print(validX.shape, validY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Next, we take the 10k dimensional tfidf's as input, and keep the 2000 dimensions that correlate the most with our sentiment target. The corresponding words - see below - make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00785785 -0.02112479  0.01765996 ...  0.01993091  0.02072059\n",
      "  0.00056014]\n"
     ]
    }
   ],
   "source": [
    "getCorrelation = np.vectorize(lambda x: pearsonr(trainX[:,x], trainY)[0])\n",
    "correlations = getCorrelation(np.arange(trainX.shape[1]))\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "allIndeces = np.argsort(-correlations)\n",
    "bestIndeces = allIndeces[np.concatenate([np.arange(1000), np.arange(-1000, 0)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great' 'love' 'excellent' 'beautiful' 'best' 'perfect' 'enjoy' 'amazing'\n",
      " 'favorite' 'performance']\n",
      "['horrible' 'poor' 'stupid' 'terrible' 'worse' 'boring' 'awful' 'waste'\n",
      " 'worst' 'bad']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = np.array(tfidf.get_feature_names())\n",
    "print(vocabulary[bestIndeces][:10])\n",
    "print(vocabulary[bestIndeces][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX[:,bestIndeces]\n",
    "validX = validX[:,bestIndeces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 2000) (15000,)\n",
      "(10000, 2000) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape)\n",
    "print(validX.shape, validY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [(15000,)], test: [(15000, 2000)]\n",
      "train: [(15000, 2000)], test: [(15000,)]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "# data sample\n",
    "data = array([trainX.shape,trainY.shape])\n",
    "# prepare cross validation\n",
    "kfold = KFold(2, True, 1)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(data):\n",
    "\tprint('train: %s, test: %s' % (data[train], data[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.5\n",
    "ACTIVATION = \"tanh\"\n",
    "\n",
    "model = Sequential([    \n",
    "    Dense(int(trainX.shape[1]/2), activation=ACTIVATION, input_dim=trainX.shape[1]),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(int(trainX.shape[1]/2), activation=ACTIVATION, input_dim=trainX.shape[1]),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(int(trainX.shape[1]/4), activation=ACTIVATION),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(100, activation=ACTIVATION),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(20, activation=ACTIVATION),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(5, activation=ACTIVATION),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 3,554,731\n",
      "Trainable params: 3,554,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(0.00005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 7\n",
    "BATCHSIZE = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "15000/15000 [==============================] - 17s 1ms/step - loss: 0.7015 - acc: 0.5069 - val_loss: 0.6852 - val_acc: 0.6521\n",
      "Epoch 2/7\n",
      "15000/15000 [==============================] - 9s 613us/step - loss: 0.6918 - acc: 0.5335 - val_loss: 0.6747 - val_acc: 0.7466\n",
      "Epoch 3/7\n",
      "15000/15000 [==============================] - 9s 633us/step - loss: 0.6832 - acc: 0.5487 - val_loss: 0.6633 - val_acc: 0.7833\n",
      "Epoch 4/7\n",
      "15000/15000 [==============================] - 9s 628us/step - loss: 0.6685 - acc: 0.5785 - val_loss: 0.6495 - val_acc: 0.7983\n",
      "Epoch 5/7\n",
      "15000/15000 [==============================] - 9s 630us/step - loss: 0.6566 - acc: 0.6072 - val_loss: 0.6320 - val_acc: 0.8075\n",
      "Epoch 6/7\n",
      "15000/15000 [==============================] - 9s 614us/step - loss: 0.6408 - acc: 0.6393 - val_loss: 0.6101 - val_acc: 0.8168\n",
      "Epoch 7/7\n",
      "15000/15000 [==============================] - 9s 604us/step - loss: 0.6192 - acc: 0.6720 - val_loss: 0.5828 - val_acc: 0.8239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26a64160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=EPOCHS, batch_size=BATCHSIZE, validation_data=(validX, validY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "size": 5
         },
         "name": "Train Accuracy",
         "type": "scatter",
         "uid": "d77af3c2-37a8-4a8b-9f94-36f2ea322fd4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          0.5069333434104919,
          0.5334666669368744,
          0.5487333357334137,
          0.5784666776657105,
          0.6071999967098236,
          0.6392666637897492,
          0.671999990940094
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "size": 5
         },
         "name": "Valid Accuracy",
         "type": "scatter",
         "uid": "0c9993b1-920d-40ff-9e9c-e6630e259cbe",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          0.652099996805191,
          0.746599993109703,
          0.7833000093698501,
          0.7983000040054321,
          0.8075000017881393,
          0.8168000012636185,
          0.8238999962806701
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "size": 5
         },
         "name": "Train Loss",
         "type": "scatter",
         "uid": "2d5b393e-3c55-4001-aa99-cc5702b486d4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          0.7015417516231537,
          0.6917938232421875,
          0.6831617891788483,
          0.6685416996479034,
          0.6566367506980896,
          0.640791779756546,
          0.6191892743110656
         ]
        },
        {
         "marker": {
          "size": 5
         },
         "name": "Valid Loss",
         "type": "scatter",
         "uid": "8b675d7f-70b9-492e-a054-cf0655690af7",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          0.6851657837629318,
          0.6747213125228881,
          0.6632887274026871,
          0.6495274007320404,
          0.6320119649171829,
          0.6100667506456375,
          0.5828084796667099
         ]
        }
       ],
       "layout": {
        "font": {
         "family": "Palatino"
        },
        "title": "Model Training Evolution",
        "xaxis": {
         "dtick": 1,
         "title": "Epoch"
        },
        "yaxis": {
         "domain": [
          0,
          0.45
         ],
         "title": "Loss"
        },
        "yaxis2": {
         "domain": [
          0.55,
          1
         ],
         "title": "Accuracy"
        }
       }
      },
      "text/html": [
       "<div id=\"1a5c8a1c-f1a6-48ce-b222-85ae1b366753\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1a5c8a1c-f1a6-48ce-b222-85ae1b366753\", [{\"marker\": {\"size\": 5}, \"name\": \"Train Accuracy\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.5069333434104919, 0.5334666669368744, 0.5487333357334137, 0.5784666776657105, 0.6071999967098236, 0.6392666637897492, 0.671999990940094], \"yaxis\": \"y2\", \"type\": \"scatter\", \"uid\": \"d77af3c2-37a8-4a8b-9f94-36f2ea322fd4\"}, {\"marker\": {\"size\": 5}, \"name\": \"Valid Accuracy\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.652099996805191, 0.746599993109703, 0.7833000093698501, 0.7983000040054321, 0.8075000017881393, 0.8168000012636185, 0.8238999962806701], \"yaxis\": \"y2\", \"type\": \"scatter\", \"uid\": \"0c9993b1-920d-40ff-9e9c-e6630e259cbe\"}, {\"marker\": {\"size\": 5}, \"name\": \"Train Loss\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.7015417516231537, 0.6917938232421875, 0.6831617891788483, 0.6685416996479034, 0.6566367506980896, 0.640791779756546, 0.6191892743110656], \"type\": \"scatter\", \"uid\": \"2d5b393e-3c55-4001-aa99-cc5702b486d4\"}, {\"marker\": {\"size\": 5}, \"name\": \"Valid Loss\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.6851657837629318, 0.6747213125228881, 0.6632887274026871, 0.6495274007320404, 0.6320119649171829, 0.6100667506456375, 0.5828084796667099], \"type\": \"scatter\", \"uid\": \"8b675d7f-70b9-492e-a054-cf0655690af7\"}], {\"font\": {\"family\": \"Palatino\"}, \"title\": \"Model Training Evolution\", \"xaxis\": {\"dtick\": 1, \"title\": \"Epoch\"}, \"yaxis\": {\"domain\": [0, 0.45], \"title\": \"Loss\"}, \"yaxis2\": {\"domain\": [0.55, 1], \"title\": \"Accuracy\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"1a5c8a1c-f1a6-48ce-b222-85ae1b366753\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"1a5c8a1c-f1a6-48ce-b222-85ae1b366753\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1a5c8a1c-f1a6-48ce-b222-85ae1b366753\", [{\"marker\": {\"size\": 5}, \"name\": \"Train Accuracy\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.5069333434104919, 0.5334666669368744, 0.5487333357334137, 0.5784666776657105, 0.6071999967098236, 0.6392666637897492, 0.671999990940094], \"yaxis\": \"y2\", \"type\": \"scatter\", \"uid\": \"d77af3c2-37a8-4a8b-9f94-36f2ea322fd4\"}, {\"marker\": {\"size\": 5}, \"name\": \"Valid Accuracy\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.652099996805191, 0.746599993109703, 0.7833000093698501, 0.7983000040054321, 0.8075000017881393, 0.8168000012636185, 0.8238999962806701], \"yaxis\": \"y2\", \"type\": \"scatter\", \"uid\": \"0c9993b1-920d-40ff-9e9c-e6630e259cbe\"}, {\"marker\": {\"size\": 5}, \"name\": \"Train Loss\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.7015417516231537, 0.6917938232421875, 0.6831617891788483, 0.6685416996479034, 0.6566367506980896, 0.640791779756546, 0.6191892743110656], \"type\": \"scatter\", \"uid\": \"2d5b393e-3c55-4001-aa99-cc5702b486d4\"}, {\"marker\": {\"size\": 5}, \"name\": \"Valid Loss\", \"x\": [0, 1, 2, 3, 4, 5, 6], \"y\": [0.6851657837629318, 0.6747213125228881, 0.6632887274026871, 0.6495274007320404, 0.6320119649171829, 0.6100667506456375, 0.5828084796667099], \"type\": \"scatter\", \"uid\": \"8b675d7f-70b9-492e-a054-cf0655690af7\"}], {\"font\": {\"family\": \"Palatino\"}, \"title\": \"Model Training Evolution\", \"xaxis\": {\"dtick\": 1, \"title\": \"Epoch\"}, \"yaxis\": {\"domain\": [0, 0.45], \"title\": \"Loss\"}, \"yaxis2\": {\"domain\": [0.55, 1], \"title\": \"Accuracy\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"1a5c8a1c-f1a6-48ce-b222-85ae1b366753\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(EPOCHS)\n",
    "history = model.history.history\n",
    "\n",
    "data = [\n",
    "    go.Scatter(x=x, y=history[\"acc\"], name=\"Train Accuracy\", marker=dict(size=5), yaxis='y2'),\n",
    "    go.Scatter(x=x, y=history[\"val_acc\"], name=\"Valid Accuracy\", marker=dict(size=5), yaxis='y2'),\n",
    "    go.Scatter(x=x, y=history[\"loss\"], name=\"Train Loss\", marker=dict(size=5)),\n",
    "    go.Scatter(x=x, y=history[\"val_loss\"], name=\"Valid Loss\", marker=dict(size=5))\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title=\"Model Training Evolution\", font=dict(family='Palatino'), xaxis=dict(title='Epoch', dtick=1),\n",
    "    yaxis1=dict(title=\"Loss\", domain=[0, 0.45]), yaxis2=dict(title=\"Accuracy\", domain=[0.55, 1]),\n",
    ")\n",
    "py.iplot(go.Figure(data=data, layout=layout), show_link=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Accuracy AND LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e364aa2c3698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"probability\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"truth\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "train[\"probability\"] = model.predict(trainX)\n",
    "train[\"prediction\"] = train.probability-0.5>0\n",
    "train[\"truth\"] = train.label==1\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 7s 459us/step\n",
      "[0.28194266799290973, 0.9213333333015442]\n",
      "0.9213333333333333\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(trainX, trainY))\n",
    "print((train.truth==train.prediction).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20070</th>\n",
       "      <td>Probably the worst Dolph film ever. There's no...</td>\n",
       "      <td>0</td>\n",
       "      <td>5564_2.txt</td>\n",
       "      <td>0.131978</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>If you want just about everything you want to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6501_10.txt</td>\n",
       "      <td>0.854555</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>I was really surprised with this movie. Going ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1758_10.txt</td>\n",
       "      <td>0.134732</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22644</th>\n",
       "      <td>This film is a portrait of the half-spastic te...</td>\n",
       "      <td>0</td>\n",
       "      <td>7881_2.txt</td>\n",
       "      <td>0.141678</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>This charmingly pleasant and tenderhearted seq...</td>\n",
       "      <td>1</td>\n",
       "      <td>8473_8.txt</td>\n",
       "      <td>0.785451</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "20070  Probably the worst Dolph film ever. There's no...      0   5564_2.txt   \n",
       "8612   If you want just about everything you want to ...      1  6501_10.txt   \n",
       "3341   I was really surprised with this movie. Going ...      1  1758_10.txt   \n",
       "22644  This film is a portrait of the half-spastic te...      0   7881_2.txt   \n",
       "10802  This charmingly pleasant and tenderhearted seq...      1   8473_8.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "20070     0.131978       False  False  \n",
       "8612      0.854555        True   True  \n",
       "3341      0.134732       False   True  \n",
       "22644     0.141678       False  False  \n",
       "10802     0.785451        True   True  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[\"probability\"] = model.predict(validX)\n",
    "valid[\"prediction\"] = valid.probability-0.5>0\n",
    "valid[\"truth\"] = valid.label==1\n",
    "valid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 467us/step\n",
      "[0.34729949016571043, 0.8717]\n",
      "0.8717\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(validX, validY))\n",
    "print((valid.truth==valid.prediction).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>truth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>6911</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>553</td>\n",
       "      <td>6909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "truth       False  True \n",
       "prediction              \n",
       "False        6911    627\n",
       "True          553   6909"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainCross = train.groupby([\"prediction\", \"truth\"]).size().unstack()\n",
    "trainCross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>truth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>4400</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>636</td>\n",
       "      <td>4317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "truth       False  True \n",
       "prediction              \n",
       "False        4400    647\n",
       "True          636   4317"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validCross = valid.groupby([\"prediction\", \"truth\"]).size().unstack()\n",
    "validCross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4317 true positives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10694</th>\n",
       "      <td>One of the best movies out there. Yeah maybe t...</td>\n",
       "      <td>1</td>\n",
       "      <td>8376_10.txt</td>\n",
       "      <td>0.870353</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>This is a taut suspenseful masterpiece from Br...</td>\n",
       "      <td>1</td>\n",
       "      <td>6856_10.txt</td>\n",
       "      <td>0.870348</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>If you have not seen this excellent movie abou...</td>\n",
       "      <td>1</td>\n",
       "      <td>4312_10.txt</td>\n",
       "      <td>0.870308</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "10694  One of the best movies out there. Yeah maybe t...      1  8376_10.txt   \n",
       "9005   This is a taut suspenseful masterpiece from Br...      1  6856_10.txt   \n",
       "6180   If you have not seen this excellent movie abou...      1  4312_10.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "10694     0.870353        True   True  \n",
       "9005      0.870348        True   True  \n",
       "6180      0.870308        True   True  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truepositives = valid[(valid.truth==True)&(valid.truth==valid.prediction)]\n",
    "print(len(truepositives), \"true positives.\")\n",
    "truepositives.sort_values(\"probability\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400 true negatives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16094</th>\n",
       "      <td>Must have to agree with the other reviewer. Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1986_1.txt</td>\n",
       "      <td>0.129942</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23041</th>\n",
       "      <td>This film was positively the worst film I have...</td>\n",
       "      <td>0</td>\n",
       "      <td>8238_1.txt</td>\n",
       "      <td>0.129966</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23196</th>\n",
       "      <td>This movie is most possibly the worst movie I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8378_1.txt</td>\n",
       "      <td>0.129979</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label        file  \\\n",
       "16094  Must have to agree with the other reviewer. Th...      0  1986_1.txt   \n",
       "23041  This film was positively the worst film I have...      0  8238_1.txt   \n",
       "23196  This movie is most possibly the worst movie I ...      0  8378_1.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "16094     0.129942       False  False  \n",
       "23041     0.129966       False  False  \n",
       "23196     0.129979       False  False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truenegatives = valid[(valid.truth==False)&(valid.truth==valid.prediction)]\n",
    "print(len(truenegatives), \"true negatives.\")\n",
    "truenegatives.sort_values(\"probability\", ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647 false positives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12340</th>\n",
       "      <td>I wouldn't go so far as to not recommend this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9858_7.txt</td>\n",
       "      <td>0.130624</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>A bunch of American students and their tutor d...</td>\n",
       "      <td>1</td>\n",
       "      <td>5205_7.txt</td>\n",
       "      <td>0.130877</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12303</th>\n",
       "      <td>This flick is sterling example of the state of...</td>\n",
       "      <td>1</td>\n",
       "      <td>9824_10.txt</td>\n",
       "      <td>0.131126</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "12340  I wouldn't go so far as to not recommend this ...      1   9858_7.txt   \n",
       "7172   A bunch of American students and their tutor d...      1   5205_7.txt   \n",
       "12303  This flick is sterling example of the state of...      1  9824_10.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "12340     0.130624       False   True  \n",
       "7172      0.130877       False   True  \n",
       "12303     0.131126       False   True  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falsepositives = valid[(valid.truth==True)&(valid.truth!=valid.prediction)]\n",
    "print(len(falsepositives), \"false positives.\")\n",
    "falsepositives.sort_values(\"probability\", ascending=True).head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636 false negatives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14449</th>\n",
       "      <td>this is a great movie. I love the series on tv...</td>\n",
       "      <td>0</td>\n",
       "      <td>11755_3.txt</td>\n",
       "      <td>0.869631</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14715</th>\n",
       "      <td>I was so excited and hyped up about watching t...</td>\n",
       "      <td>0</td>\n",
       "      <td>11995_4.txt</td>\n",
       "      <td>0.868042</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19440</th>\n",
       "      <td>this one of the best celebrity's reality shows...</td>\n",
       "      <td>0</td>\n",
       "      <td>4998_3.txt</td>\n",
       "      <td>0.867258</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "14449  this is a great movie. I love the series on tv...      0  11755_3.txt   \n",
       "14715  I was so excited and hyped up about watching t...      0  11995_4.txt   \n",
       "19440  this one of the best celebrity's reality shows...      0   4998_3.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "14449     0.869631        True  False  \n",
       "14715     0.868042        True  False  \n",
       "19440     0.867258        True  False  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falsenegatives = valid[(valid.truth==False)&(valid.truth!=valid.prediction)]\n",
    "print(len(falsenegatives), \"false negatives.\")\n",
    "falsenegatives.sort_values(\"probability\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Application\n",
    "Custom Reviews\n",
    "To use this model, we would store the model, along with the preprocessing vectorizers, and run the unseen texts through following pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = pd.Series(\"this movie very good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed.\n"
     ]
    }
   ],
   "source": [
    "unseen = preprocess.transform(unseen)       # Text preprocessing\n",
    "unseen = tfidf.transform(unseen).toarray()  # Feature engineering\n",
    "unseen = unseen[:,bestIndeces]              # Feature selection\n",
    "probability = model.predict(unseen)[0,0]  # Network feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67211\n",
      "Positive!\n"
     ]
    }
   ],
   "source": [
    "print(probability)\n",
    "print(\"Positive!\") if probability > 0.5 else print(\"Negative!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
